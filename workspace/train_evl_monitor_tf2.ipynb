{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46fed58e-9fa0-4b13-afaf-2d46c4c7a802",
   "metadata": {},
   "source": [
    "# Import Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a73152d-3715-4856-940f-98bb2ba9d1db",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import regex as re\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, interactive\n",
    "from ipywidgets import AppLayout, Button, Layout, Box, FloatText, Textarea, Dropdown, Label, IntSlider\n",
    "from IPython.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "from ipyfilechooser import FileChooser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d29bc44-8e74-479d-aec7-0c828efe6d75",
   "metadata": {},
   "source": [
    "# Configure the Training Pipeline\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b864bc05-b826-4330-83c6-fe075159ca78",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config_pipeline():\n",
    "    \n",
    "    def __init__(self, training_dir, my_model_directory_name, fine_tune_checkpoint,\n",
    "                record_folder, label_map_pbtxt_fname, batch_size, num_steps, image_resizer, use_pretrain):\n",
    "        self.training_dir = training_dir\n",
    "        self.my_model_directory_name = my_model_directory_name\n",
    "        self.fine_tune_checkpoint = fine_tune_checkpoint\n",
    "        self.train_record_fname = record_folder + r'/train.record'\n",
    "        self.test_record_fname  = record_folder + r'/test.record'\n",
    "        self.label_map_pbtxt_fname = label_map_pbtxt_fname\n",
    "        self.batch_size = batch_size\n",
    "        self.num_steps = num_steps\n",
    "        self.image_resizer = image_resizer.split('X')[0]\n",
    "        self.num_classes = 1\n",
    "        self.use_pretrain = use_pretrain\n",
    "        \n",
    "        self.home_path = os.getcwd() \n",
    "        self.path_para_list = [self.my_model_directory_name, self.fine_tune_checkpoint, self.train_record_fname, self.test_record_fname, self.label_map_pbtxt_fname]\n",
    "        self.update_path_para_list = list(map(lambda x : os.path.join(self.home_path, self.training_dir, x), self.path_para_list))  #update the\n",
    "        \n",
    "    def run_update(self):\n",
    "        self.num_classes = self.get_num_classes(self.update_path_para_list[4])\n",
    "        print('The number of class: {}'.format(self.num_classes))\n",
    "        # create model_directory            \n",
    "        self.create_user_folder(self.update_path_para_list[0])\n",
    "        # copy pipeline.config\n",
    "        self.update_config(self.update_path_para_list[1].split(r'checkpoint')[-2], self.update_path_para_list[0])\n",
    "    \n",
    "    def get_num_classes(self, pbtxt_fname):\n",
    "        label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "        categories = label_map_util.convert_label_map_to_categories(\n",
    "            label_map, max_num_classes=90, use_display_name=True)\n",
    "        category_index = label_map_util.create_category_index(categories)\n",
    "        return len(category_index.keys())\n",
    "    \n",
    "    def create_user_folder(self, dir_path):\n",
    "        try:\n",
    "            os.mkdir(dir_path)\n",
    "        except OSError as error:\n",
    "            print(error)\n",
    "            print('skip create...')\n",
    "    def copy_user_file(self, src, dst):\n",
    "        try:\n",
    "            shutil.copy(src, dst)\n",
    "        except OSError as error:\n",
    "            print(error)\n",
    "    def update_config(self, src_fld, dst_fld):\n",
    "        print('writing custom configuration file...')\n",
    "    \n",
    "        with open(os.path.join(src_fld, 'pipeline.config')) as f:\n",
    "            s = f.read()\n",
    "        print('The train config file is at: {}'.format(os.path.join(dst_fld, 'pipeline.config')))    \n",
    "        with open(os.path.join(dst_fld, 'pipeline.config'), 'w') as f:\n",
    "            \n",
    "            # fine_tune_checkpoint\n",
    "            if self.use_pretrain:\n",
    "                s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "                           'fine_tune_checkpoint: \"{}\"'.format(self.fine_tune_checkpoint), s)\n",
    "            else:\n",
    "                s = re.sub('fine_tune_checkpoint: \".*?\"', '', s)\n",
    "            # label_map_path\n",
    "            s = re.sub(\n",
    "                'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(self.label_map_pbtxt_fname), s)\n",
    "            # Set training batch_size.\n",
    "            s = re.sub('batch_size: [0-9]+',\n",
    "                       'batch_size: {}'.format(self.batch_size), s)\n",
    "            # Set training steps, num_steps\n",
    "            s = re.sub('num_steps: [0-9]+',\n",
    "                       'num_steps: {}'.format(self.num_steps), s)\n",
    "            # Set number of classes num_classes.\n",
    "            s = re.sub('num_classes: [0-9]+',\n",
    "                       'num_classes: {}'.format(self.num_classes), s)\n",
    "            # Set number of fixed_shape_resizer.\n",
    "            s = re.sub('height: [0-9]+',\n",
    "                       'height: {}'.format(self.image_resizer), s)\n",
    "            s = re.sub('width: [0-9]+',\n",
    "                       'width: {}'.format(self.image_resizer), s)\n",
    "            #fine-tune checkpoint type\n",
    "            s = re.sub(\n",
    "                'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
    "            \n",
    "            # tfrecord files train and test. (the train section must before test section)\n",
    "            s = re.sub(\n",
    "                '(input_path: \".*?)(PATH_TO_BE_CONFIGURED)(.*?\")', 'input_path: \"{}\"'.format(self.train_record_fname), s, 1)\n",
    "            s = re.sub(\n",
    "                '(input_path: \".*?)(PATH_TO_BE_CONFIGURED)(.*?\")', 'input_path: \"{}\"'.format(self.test_record_fname), s, 1)\n",
    "            \n",
    "            f.write(s)            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ae9c70-0817-4ff5-91c1-9db7ea52cf20",
   "metadata": {},
   "source": [
    "# Widgets Control Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad741c2f-f6f5-45bb-b861-85e1964cda82",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class train_config_and_cmds_widgets():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.tflite_file_loc = \"\"\n",
    "        \n",
    "        form_item_layout = Layout(\n",
    "        display='flex',\n",
    "        flex_flow='row',\n",
    "        justify_content='space-between',\n",
    "        )\n",
    "        \n",
    "        ### open source data download###\n",
    "        self.A_ta = widgets.Text(value='training_demo', placeholder='Type something', disabled=False)\n",
    "        self.B_ta = widgets.Text(value='models/my_ssd_mobilenet_v2_fpnlite', placeholder='Type something', disabled=False)\n",
    "        self.J_ta = widgets.Checkbox(value=True, disabled=False, indent=False)\n",
    "        self.C_ta = widgets.Textarea(value='pre-trained-models/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0', \n",
    "                                     placeholder='Type something', disabled=False)\n",
    "        self.D_ta = widgets.Text(value='annotations', placeholder='Type something', disabled=False)\n",
    "        self.E_ta = widgets.Text(value='annotations/label_map.pbtxt', placeholder='Type something', disabled=False)\n",
    "        self.F_ta = widgets.IntSlider(value=16, min=8, max=72, step=4)\n",
    "        self.G_ta = widgets.Text(value='50000', placeholder='Type something', disabled=False)\n",
    "        self.H_ta = Dropdown(options=['320X320', '240X240', '180X180', '120X120', '80X80', '60X60'])\n",
    "        self.I_ta = widgets.Text(value='exported-models/tflite_infer_graph', placeholder='Type something', disabled=False)\n",
    "        \n",
    "        form_pretrain_itesms = [Box([Label(value = 'Use pre-train model'), self.J_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Fine Tune Checkpoint'), self.C_ta], layout=form_item_layout)]\n",
    "        \n",
    "        form_train_items = [\n",
    "            Box([Label(value = 'Your Working Directory Name'), self.A_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'My Model Directory Name'), self.B_ta], layout=form_item_layout),\n",
    "            Box(form_pretrain_itesms, layout=Layout(\n",
    "            display='flex',\n",
    "            flex_flow='column',\n",
    "            border='solid 1px lightblue',    \n",
    "        )),\n",
    "            Box([Label(value = 'Train Record Folder'), self.D_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Label Map Pbtxt'), self.E_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Batch Size'), self.F_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Number Steps'), self.G_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Image Resizer'), self.H_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Output Folder'), self.I_ta], layout=form_item_layout)\n",
    "        ]\n",
    "        \n",
    "        self.form_output_train_cmd = Box(form_train_items, layout=Layout(\n",
    "            display='flex',\n",
    "            flex_flow='column',\n",
    "            border='solid 3px lightgreen',\n",
    "            align_items='stretch',\n",
    "            width='50%',\n",
    "        ))\n",
    "        \n",
    "    def move_allfiles(self, src_folder, dst_folder):\n",
    "        copy_num = 0\n",
    "        \n",
    "        files = os.listdir(src_folder)\n",
    "        for f in files:\n",
    "            fullpath = os.path.join(src_folder, f)\n",
    "            if os.path.isdir(fullpath):  #copy whole folder\n",
    "                shutil.move(fullpath, dst_folder)\n",
    "                print(\"Copy finish: {}\".format(f))\n",
    "    \n",
    "    def show_headline(self, output):\n",
    "        html0= widgets.HTML(value = f\"<b><font color='lightblue'><font size=4>{output}</b>\")\n",
    "        display(html0)\n",
    "    \n",
    "    def show_main(self):   \n",
    "        \n",
    "        intro_text = 'Please Choose the setting of train config'\n",
    "        htmlWidget = widgets.HTML(value = f\"<b><font color='lightgreen'><font size=6>{intro_text}</b>\")\n",
    "        display(htmlWidget)\n",
    "        \n",
    "        #Create an accordion and put the 2 boxes\n",
    "        accordion = widgets.Accordion(children=[self.form_output_train_cmd \n",
    "                                                ]).add_class(\"parentstyle\")\n",
    "        #Add a custom style tag to the notebook, you can use dev tool to inspect the class names\n",
    "        display(HTML(\"<style>.parentstyle > .p-Accordion-child > .p-Collapse-header{background-color:green}</style>\"))\n",
    "        accordion.set_title(0, 'Configure the Training')\n",
    "        \n",
    "        def act_para(training_dir, my_model_directory_name, fine_tune_checkpoint,\n",
    "                     record_folder, label_map_pbtxt_fname, batch_size, \n",
    "                     num_steps, image_resizer, output_dir, use_pretrain):\n",
    "            #------------------#\n",
    "            # The main executing Toggle_Button\n",
    "            #------------------#\n",
    "            toggle_update_config = widgets.ToggleButton(description='Update the config', \n",
    "                                                   layout=Layout(width='30%', height='30px'), button_style='success')\n",
    "            toggle_create_cmd = widgets.ToggleButton(description='Create The Commands', \n",
    "                                                   layout=Layout(width='30%', height='30px'), button_style='success')\n",
    "            out = widgets.Output(layout=Layout(border = '1px solid green'))\n",
    "            \n",
    "            if use_pretrain:\n",
    "                self.C_ta.layout.visibility = 'visible'\n",
    "            else:\n",
    "                self.C_ta.layout.visibility = 'hidden'  \n",
    "            \n",
    "            \n",
    "            #------------------#\n",
    "            # The main executing Toggle_Button's event function\n",
    "            #------------------#\n",
    "            def run_update_config(obj):\n",
    "                with out:\n",
    "                    if obj['new']:\n",
    "                        out.clear_output()\n",
    "                        print('Update training config...')\n",
    "                        config_obj = config_pipeline(training_dir, my_model_directory_name, fine_tune_checkpoint,\n",
    "                                                     record_folder, label_map_pbtxt_fname, batch_size, \n",
    "                                                     num_steps, image_resizer, use_pretrain)\n",
    "                        config_obj.run_update()\n",
    "                        \n",
    "                        print('Finish')\n",
    "                    else:\n",
    "                        print('stop')\n",
    "                        out.clear_output() \n",
    "            \n",
    "            def run_create_cmd(obj):\n",
    "                with out:\n",
    "                    if obj['new']:\n",
    "                        out.clear_output()\n",
    "                        self.show_headline('Please copy these commands to the CMD.exe Prompt to execute. ')\n",
    "                        pipeline_config_path = (my_model_directory_name + r'/pipeline.config')\n",
    "                        checkpoint_dir = my_model_directory_name\n",
    "                        output_directory = output_dir\n",
    "                        try:\n",
    "                            os.mkdir(os.path.join(os.getcwd(), training_dir, output_directory))\n",
    "                        except OSError as error:\n",
    "                            #print(error)\n",
    "                            print('skip create...')\n",
    "                        \n",
    "                        self.show_headline('(1.) Please excute the below 2~5 commands under the working directory')\n",
    "                        print(\"cd {}\".format(os.path.join(os.getcwd(), training_dir)))\n",
    "                        \n",
    "                        self.show_headline('(2.) Train:')\n",
    "                        train_cmd = \"python model_main_tf2.py --model_dir={} --pipeline_config_path={}\".format(my_model_directory_name, \n",
    "                                    pipeline_config_path)\n",
    "                        print(train_cmd)\n",
    "                        \n",
    "                        self.show_headline('(3.) Evaluating the Model (Optional):')\n",
    "                        evl_cmd = \"python model_main_tf2.py --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(my_model_directory_name, \n",
    "                                    pipeline_config_path, checkpoint_dir)\n",
    "                        print(evl_cmd)\n",
    "                        \n",
    "                        self.show_headline('(4.) Monitor Training:')\n",
    "                        monitor_cmd = \"tensorboard --logdir={}\".format(my_model_directory_name)    \n",
    "                        print(monitor_cmd)\n",
    "                        \n",
    "                        self.show_headline('(5.) Export a tflite inference graph:')\n",
    "                        export_graph_cmd = \"python export_tflite_graph_tf2.py --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={} \".format(pipeline_config_path, checkpoint_dir, output_directory)    \n",
    "                        print(export_graph_cmd)\n",
    "                        \n",
    "                    else:\n",
    "                        print('stop')\n",
    "                        out.clear_output() \n",
    "            \n",
    "            toggle_update_config.observe(run_update_config, 'value')\n",
    "            toggle_create_cmd.observe(run_create_cmd, 'value')\n",
    "            display(toggle_update_config, toggle_create_cmd)\n",
    "            display(out)\n",
    "            \n",
    "        \n",
    "        #------------------#\n",
    "        # widgets.Accordion's interactive input with action function `act_para()`\n",
    "        #------------------#\n",
    "        out_inter = widgets.interactive_output(act_para, {'training_dir': self.A_ta, 'my_model_directory_name': self.B_ta, 'fine_tune_checkpoint': self.C_ta, \n",
    "                                                          'record_folder': self.D_ta, 'label_map_pbtxt_fname': self.E_ta, 'batch_size': self.F_ta, \n",
    "                                                          'num_steps': self.G_ta, 'image_resizer': self.H_ta, \n",
    "                                                          'output_dir': self.I_ta, 'use_pretrain': self.J_ta\n",
    "                                                          })\n",
    "        display(accordion, out_inter)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df117bd1-f25c-4dd1-8117-1c867acb6fdb",
   "metadata": {},
   "source": [
    "# Run Section\n",
    "---\n",
    "- The detail description of all the parameters and each step meaning is here [meaning](#id-train_evl_monitor)\n",
    "- In this notebook step, you have alreay finish the dataset prepared. If not, please go to `image_dataset\\create_data.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "549dff3b-b351-488d-a53d-dcb4b721061e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1aee83ac6ea4553b4fe9267e378f80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<b><font color='lightgreen'><font size=6>Please Choose the setting of train config</b>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.parentstyle > .p-Accordion-child > .p-Collapse-header{background-color:green}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457588678d17476387bb57a0f0390662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Box(children=(Box(children=(Label(value='Your Working Directory Name'), Text(value='traini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c270f4fff1e45408351a418466ffc66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "act = train_config_and_cmds_widgets()\n",
    "act.show_main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c895d2ff-d998-4b5b-a27e-868b8b323b54",
   "metadata": {},
   "source": [
    "<a id=\"id-train_evl_monitor\"></a>\n",
    "# Parameter & Steps Description\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4bda91-e761-4268-9c2f-32b71986c579",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "### Issue\n",
    "- If you use GPU and meet `error: Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice`. Please execute below cmd before training.\n",
    "- `set XLA_FLAGS=--xla_gpu_cuda_data_dir=\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.8\"`\n",
    "### Download Pre-Trained Model\n",
    "- The model in this demo is the `SSD MobileNet V2 FPNLite 320x320` which is already in `pre-trained-models/` \n",
    "- All of the tensorflow2 pre-trained models are listed in [TensorFlow 2 Detection Model Zoo](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md), and you can download each of them.\n",
    "- The download file is `*.tar.gz`, and please decompression it (e.g. 7zip, WinZIP, etc.).\n",
    "- Move the decompression folder into `<Your Woking Folder>/pre-trained-models`\n",
    "\n",
    "- <pre>training_demo/\n",
    "├─ ...\n",
    "├─ pre-trained-models/\n",
    "│  └─ ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
    "│     ├─ checkpoint/\n",
    "│     ├─ saved_model/\n",
    "│     └─ pipeline.config\n",
    "└─ ...\n",
    "</pre>\n",
    "### Configure the Training\n",
    "- The parameters below is basing on your files/folders nameing. Please update them if any change.\n",
    "    1. `Your Working Directory Name`: The user defined working directory\n",
    "    2. `My Model Directory Name`: The location of user defined which save the training's weights, checkpoints and config file\n",
    "    3. `Fine Tune Checkpoint`: The location of downloaded pre-trained-models checkpoint\n",
    "    4. `Train Record Folder`: The folder location of created tfrecord for training & testing\n",
    "    6. `Label Map Pbtxt`: The file location of label map\n",
    "    7. `Batch Size`: Tune this value depending on the available memory.\n",
    "    8. `Number Steps`: How many the training steps.\n",
    "    9. `Image Resizer`: The input layer of height & width. The smaller the accracy is lower but training/inference is faster. \n",
    "    10. `Output Folder`: The location of exporting the tflite inference graph. \n",
    "- This is for `SSD MobileNet V2 FPNLite 320x320` pipeline.config, if you use other model, the pipeline.config maybe have minor different. However, these attributes should be the same and mattered.\n",
    "- \\<Advanced>: If you want to tunning more parameters, please update `pipeline.config` directly.\n",
    "\n",
    "### Train\n",
    "- The output will normally look like it has “frozen”, but DO NOT rush to cancel the process. The training outputs logs only every 100 steps by default, therefore if you wait for a while, you should see a log for the loss at step 100.\n",
    "- <img src=\"train_exmple_plots/train_process.png\" width=\"400\" height=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649cf448-c09d-458b-b672-004b4a305290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
