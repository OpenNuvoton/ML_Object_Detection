{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d43d87a7-9e74-47bf-8d7b-2571639b543d",
   "metadata": {},
   "source": [
    "# Import Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30712307-e0e9-4599-a2ab-4af6ba2527a2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import regex as re\n",
    "import shutil\n",
    "import json\n",
    "import os\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual, interactive\n",
    "from ipywidgets import AppLayout, Button, Layout, Box, FloatText, Textarea, Dropdown, Label, IntSlider\n",
    "from IPython.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "from ipyfilechooser import FileChooser\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434e24a8-473e-418d-a841-d0f11855fc13",
   "metadata": {},
   "source": [
    "# Convert the tflite\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dddbf5d8-3597-4234-9eda-0a3c592c14be",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class my_tflite_trans():\n",
    "    def __init__(self, source_model_folder, output_tflite_location, rep_dataset_loc, input_img_size):\n",
    "        self.source_model_folder = source_model_folder\n",
    "        self.output_tflite_location = output_tflite_location\n",
    "        \n",
    "        self.rep_dataset_loc = rep_dataset_loc\n",
    "        self.input_img_size = input_img_size\n",
    "        \n",
    "    def tflite_preprocess(self, image, height, width):\n",
    "        if image.dtype != tf.float32:\n",
    "            image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "    \n",
    "        # Resize the image to the specified height and width.\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        image = tf.compat.v1.image.resize_bilinear(image, [height, width],\n",
    "                                       align_corners=False)\n",
    "        #image = tf.squeeze(image, [0])\n",
    "    \n",
    "        image = tf.subtract(image, 0.5)\n",
    "        image = tf.multiply(image, 2.0)\n",
    "        return image\n",
    "    \n",
    "    def representative_dataset(self):\n",
    "        files = glob(self.rep_dataset_loc)\n",
    "        random.shuffle(files)\n",
    "        files = files[:128]\n",
    "        for file in files:\n",
    "            image = tf.io.read_file(file)\n",
    "            image = tf.compat.v1.image.decode_jpeg(image)\n",
    "            if image.get_shape()[2] == 3: # skip the not correct channel pictures\n",
    "                image = self.tflite_preprocess(image, int(self.input_img_size), int(self.input_img_size))\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            yield [image]\n",
    "\n",
    "    def run_tflite(self, quant_options):\n",
    "        # Refer to: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md#step-2-convert-to-tflite\n",
    "        print(\"Start to convert, please wait...\")\n",
    "        if quant_options == 'None':\n",
    "            output_location = self.output_tflite_location + r'.tflite'\n",
    "        elif quant_options == 'Dynamic':\n",
    "            output_location = self.output_tflite_location + r'_quant.tflite'\n",
    "        elif quant_options == 'Full':\n",
    "            output_location = self.output_tflite_location + r'_fullquant.tflite'\n",
    "        elif quant_options == 'Float16':    \n",
    "            output_location = self.output_tflite_location + r'_f16quant.tflite'\n",
    "        \n",
    "        converter = tf.lite.TFLiteConverter.from_saved_model(self.source_model_folder)\n",
    "        \n",
    "        if quant_options == 'Dynamic' or quant_options == 'Full' or quant_options == 'Float16':\n",
    "            converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "            print(\"tf lite Optimize\")\n",
    "        \n",
    "        if quant_options == 'Full':\n",
    "            converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "            converter.representative_dataset = self.representative_dataset\n",
    "            converter.inference_input_type = tf.int8  # or tf.uint8\n",
    "            #converter.inference_output_type = tf.int8  # or tf.uint8 # The head of TF ssd_mobileNetv2 has dequant\n",
    "            print(\"Full quantation\")\n",
    "        \n",
    "        if quant_options == 'Float16':   \n",
    "            converter.target_spec.supported_types = [tf.float16]\n",
    "            converter.representative_dataset = self.representative_dataset\n",
    "            print(\"Float16 quantation\")\n",
    "        \n",
    "        tflite_model = converter.convert()\n",
    "          \n",
    "        # Save the model.\n",
    "        with open(output_location, 'wb') as f:\n",
    "            f.write(tflite_model)\n",
    "        print(\"The tflite output location: {}\".format(output_location))    \n",
    "        print(\"Finish!\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5984193-cb82-41df-a671-b679249cfaaa",
   "metadata": {},
   "source": [
    "# Widgets Control Section\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4126640b-49df-41bb-ae83-6cc2eb0f0e69",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class init_tflite_widgets():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.tflite_file_loc = \"\"\n",
    "        \n",
    "        form_item_layout = Layout(\n",
    "        display='flex',\n",
    "        flex_flow='row',\n",
    "        justify_content='space-between',\n",
    "        )\n",
    "        \n",
    "        ### open source data download###\n",
    "        self.A_ta = widgets.Text(value='training_demo', placeholder='Type something', disabled=False)\n",
    "        self.B_ta = widgets.Text(value=r'exported-models\\tflite_infer_graph', placeholder='Type something', disabled=False)\n",
    "        self.C_ta = widgets.Text(value='ssd_mobileNetv2', placeholder='Type something', disabled=False)\n",
    "        self.D_ta = widgets.Textarea(value=r'C:\\\\Users\\\\USERNAME\\\\image_detection\\\\TensorFlow\\\\workspace\\\\training_demo_8000\\\\images\\\\test', \n",
    "                                     placeholder='Type something', disabled=False)\n",
    "        self.G_ta = widgets.Text(value='320', placeholder='Type something', disabled=False)\n",
    "        self.E_ta = Dropdown(options=['None', 'Dynamic', 'Full', 'Float16'])\n",
    "        self.F_ta = widgets.Checkbox(value=False, disabled=False, indent=False)\n",
    "        \n",
    "         \n",
    "        form_train_items = [\n",
    "            Box([Label(value = 'Your Working Directory Name'), self.A_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Source pb Model Folder'), self.B_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Output tflite Name'), self.C_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Rep Dataset Location'), self.D_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Input Image size'), self.G_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Quantization'), self.E_ta], layout=form_item_layout),\n",
    "            Box([Label(value = 'Run All'), self.F_ta], layout=form_item_layout)\n",
    "        ]\n",
    "        \n",
    "        self.form_output_train_cmd = Box(form_train_items, layout=Layout(\n",
    "            display='flex',\n",
    "            flex_flow='column',\n",
    "            border='solid 3px lightgreen',\n",
    "            align_items='stretch',\n",
    "            width='50%',\n",
    "        ))\n",
    "        \n",
    "    def move_allfiles(self, src_folder, dst_folder):\n",
    "        copy_num = 0\n",
    "        \n",
    "        files = os.listdir(src_folder)\n",
    "        for f in files:\n",
    "            fullpath = os.path.join(src_folder, f)\n",
    "            if os.path.isdir(fullpath):  #copy whole folder\n",
    "                shutil.move(fullpath, dst_folder)\n",
    "                print(\"Copy finish: {}\".format(f))\n",
    "    \n",
    "    def show_headline(self, output):\n",
    "        html0= widgets.HTML(value = f\"<b><font color='lightblue'><font size=4>{output}</b>\")\n",
    "        display(html0)\n",
    "    \n",
    "    def show_main(self):   \n",
    "        \n",
    "        intro_text = 'Please Choose the setting of train config'\n",
    "        htmlWidget = widgets.HTML(value = f\"<b><font color='lightgreen'><font size=6>{intro_text}</b>\")\n",
    "        display(htmlWidget)\n",
    "        \n",
    "        #Create an accordion and put the 2 boxes\n",
    "        accordion = widgets.Accordion(children=[self.form_output_train_cmd \n",
    "                                                ]).add_class(\"parentstyle\")\n",
    "        #Add a custom style tag to the notebook, you can use dev tool to inspect the class names\n",
    "        display(HTML(\"<style>.parentstyle > .p-Accordion-child > .p-Collapse-header{background-color:green}</style>\"))\n",
    "        accordion.set_title(0, 'Configure the Training')\n",
    "        \n",
    "        def act_para(training_dir, source_model_folder, tflite_name,\n",
    "                    rep_dataset_folder, quant_options, run_all, input_img_size):\n",
    "            #------------------#\n",
    "            # The main executing Toggle_Button\n",
    "            #------------------#\n",
    "            toggle_convert_tflite = widgets.ToggleButton(description='Convert to tflite', \n",
    "                                                   layout=Layout(width='30%', height='30px'), button_style='success')\n",
    "            out = widgets.Output(layout=Layout(border = '1px solid green'))\n",
    "            \n",
    "            \n",
    "            #------------------#\n",
    "            # The main executing Toggle_Button's event function\n",
    "            #------------------#        \n",
    "            def run_convert_tflite(obj):\n",
    "                with out:\n",
    "                    if obj['new']:\n",
    "                        out.clear_output()\n",
    "                        self.show_headline('Converting the model graph to tflite... ')\n",
    "                        source_md = os.path.join(training_dir, source_model_folder, 'saved_model')\n",
    "                        output_tflite = os.path.join(training_dir, source_model_folder, tflite_name)\n",
    "                        rep_dataset = os.path.join(rep_dataset_folder, '*.jpg')\n",
    "                        #print(source_md)\n",
    "                        #print(output_tflite)\n",
    "                        #print(rep_dataset)\n",
    "                        if run_all:\n",
    "                            x = my_tflite_trans(source_md, output_tflite, rep_dataset, input_img_size)\n",
    "                            x.run_tflite('None')\n",
    "                            x.run_tflite('Dynamic')\n",
    "                            x.run_tflite('Full')\n",
    "                            x.run_tflite('Float16')\n",
    "                        else:\n",
    "                            x = my_tflite_trans(source_md, output_tflite, rep_dataset, input_img_size)\n",
    "                            x.run_tflite(quant_options)\n",
    "                        \n",
    "                    else:\n",
    "                        print('stop')\n",
    "                        out.clear_output() \n",
    "            \n",
    "            toggle_convert_tflite.observe(run_convert_tflite, 'value')\n",
    "            display(toggle_convert_tflite)\n",
    "            display(out)\n",
    "            \n",
    "        \n",
    "        #------------------#\n",
    "        # widgets.Accordion's interactive input with action function `act_para()`\n",
    "        #------------------#\n",
    "        out_inter = widgets.interactive_output(act_para, {'training_dir': self.A_ta, 'source_model_folder': self.B_ta, 'tflite_name': self.C_ta, \n",
    "                                                          'rep_dataset_folder': self.D_ta, 'quant_options': self.E_ta, 'run_all': self.F_ta,\n",
    "                                                          'input_img_size': self.G_ta\n",
    "                                                          })\n",
    "        display(accordion, out_inter)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ced1ac-99c1-4a9f-b9eb-a7297ffb8c59",
   "metadata": {},
   "source": [
    "# Run Section\n",
    "---\n",
    "- The detail description of all the parameters and each step meaning is here [meaning](#id-train_evl_monitor)\n",
    "- In this notebook step, you have alreay finish the train. If not, please go to `workspace\\train_evl_monitor.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9410917-3a18-4762-b71a-e0423c8a864e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c07fbc76bd94706bf864b92dc49ec7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value=\"<b><font color='lightgreen'><font size=6>Please Choose the setting of train config</b>\")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.parentstyle > .p-Accordion-child > .p-Collapse-header{background-color:green}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a5b29e6dc449eea3c2a28f457b5c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(Box(children=(Box(children=(Label(value='Your Working Directory Name'), Text(value='traini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f412dbceec1146559e115bb35738744f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "act = init_tflite_widgets()\n",
    "act.show_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed927b04-9ba1-461b-a8a2-bb80f4085dde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
